{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/renjie/Documents/MTech/AY1819Sem1/KE5208_SenseMakingAndInsightsDiscovery/CA'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(os.path.join(os.getcwd(), '..'))\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/renjie/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from src.utils import get_dataset\n",
    "from src.utils import select_data\n",
    "\n",
    "import scipy.io as sio\n",
    "from scipy.signal import resample\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import UpSampling1D\n",
    "from keras.layers import Concatenate\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join(os.getcwd(), 'data')\n",
    "os.listdir(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_path, _,inertial_path, skeleton_path,rgb_path = get_dataset(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = list(range(1,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_subject(d_path, subject):\n",
    "    select_statement = '_s{}_'.format(subject)\n",
    "    subjects = []\n",
    "    for i in d_path:\n",
    "        if select_statement in i:\n",
    "            subjects.append(i)\n",
    "    return subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action_number(single_path):\n",
    "    return int(single_path.split('/')[-1].split('_')[0][1:])\n",
    "def get_subject_number(single_path):\n",
    "    return int(single_path.split('/')[-1].split('_')[1][1:])\n",
    "def get_trial_number(single_path):\n",
    "    return int(single_path.split('/')[-1].split('_')[2][1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_len_inertial(inertial_d):\n",
    "    inertial_d = np.swapaxes(inertial_d, 0,1)\n",
    "    inertial_d = sequence.pad_sequences(inertial_d, maxlen=326)\n",
    "    inertial_d = np.swapaxes(inertial_d, 0,1)\n",
    "    return inertial_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on subject 1,3,5,7\n",
    "# test on subject 2,4,6,8\n",
    "X_train = []\n",
    "Y_train = []\n",
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "resample_len = 180\n",
    "\n",
    "for path in inertial_path:\n",
    "    if get_subject_number(path) in [1,3,5,7]:\n",
    "        X_train.append(path)\n",
    "        Y_train.append(get_action_number(path))\n",
    "    else:\n",
    "        X_test.append(path)\n",
    "        Y_test.append(get_action_number(path))\n",
    "\n",
    "# X_train = [pad_len_inertial(sio.loadmat(x)['d_iner']) for x in X_train]\n",
    "# X_test = [pad_len_inertial(sio.loadmat(x)['d_iner']) for x in X_test]\n",
    "\n",
    "X_train = [resample(sio.loadmat(x)['d_iner'], resample_len) for x in X_train]\n",
    "X_test = [resample(sio.loadmat(x)['d_iner'], resample_len) for x in X_test]\n",
    "\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "Y_train = to_categorical(np.array(Y_train) - 1)\n",
    "Y_test = to_categorical(np.array(Y_test) - 1)\n",
    "\n",
    "##################\n",
    "# normalize data #\n",
    "##################\n",
    "\n",
    "# X_train[:,:,3:] = X_train[:,:,3:]/ max(X_train[:,:,3:].max(), abs(X_train[:,:,3:].min()))\n",
    "# X_train[:,:,:3] = X_train[:,:,:3]/ max(X_train[:,:,:3].max(), abs(X_train[:,:,:3].min()))\n",
    "\n",
    "# X_test[:,:,3:] = X_test[:,:,3:]/ max(X_test[:,:,3:].max(), abs(X_test[:,:,3:].min()))\n",
    "# X_test[:,:,:3] = X_test[:,:,:3]/ max(X_test[:,:,:3].max(), abs(X_test[:,:,:3].min()))\n",
    "\n",
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    '''\n",
    "    Calculates the F1 by using keras.backend\n",
    "    '''\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "        Only computes a batch-wise average of recall.\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "        Only computes a batch-wise average of precision.\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "#     print(\"precision: \", precision)\n",
    "#     print(\"recall: \", recall)\n",
    "    return 2 * ((precision * recall) / (precision + recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_LSTM():\n",
    "    np.random.seed(7)\n",
    "    model = Sequential(name = 'simple_LSTM')\n",
    "    model.add(LSTM(512, input_shape=(None, 6), recurrent_dropout=0.5))\n",
    "    model.add(Dense(len(activities), activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4), metrics=['accuracy', 'mse',f1])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bidirectional_LSTM():\n",
    "    np.random.seed(7)\n",
    "    model = Sequential(name = 'bidirectional_LSTM')\n",
    "    model.add(Bidirectional(LSTM(512, recurrent_dropout=0.5), input_shape=(None, 6)))\n",
    "    model.add(Dense(len(activities), activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-3), metrics=['accuracy', 'mse',f1])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_LSTM():\n",
    "    # Create the model\n",
    "    np.random.seed(7)\n",
    "    optimizer = Adam(lr=1e-4, decay=1e-6, clipnorm=0.6)\n",
    "    model = Sequential(name = 'conv_LSTM')\n",
    "    model.add(Conv1D(128,\n",
    "                     4,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=1,\n",
    "                    input_shape=(180, 6)))\n",
    "    model.add(Conv1D(64,\n",
    "                     4,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=1))\n",
    "    #model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(64,\n",
    "                     4,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=1))\n",
    "    model.add(Conv1D(64,\n",
    "                     4,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=1))\n",
    "    model.add(LSTM(256, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(LSTM(256, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Flatten())\n",
    "    #model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(len(activities), activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_LSTM2():\n",
    "    # Create the model\n",
    "    np.random.seed(7)\n",
    "    optimizer = Adam(lr=1e-4)\n",
    "    model = Sequential(name = 'conv_LSTM2')\n",
    "    model.add(Conv1D(16,\n",
    "                     3,\n",
    "                     padding='same',\n",
    "                     activation='relu',\n",
    "                     strides=1,\n",
    "                     kernel_initializer = 'glorot_uniform',\n",
    "                    input_shape=(180, 6)))\n",
    "    model.add(Conv1D(32,\n",
    "                     3,\n",
    "                     padding='same',\n",
    "                     activation='relu',\n",
    "                     strides=1,\n",
    "                    kernel_initializer = 'glorot_uniform'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(64,\n",
    "                     3,\n",
    "                     padding='same',\n",
    "                     activation='relu',\n",
    "                     strides=1,\n",
    "                    kernel_initializer = 'glorot_uniform'))\n",
    "    model.add(Conv1D(128,\n",
    "                     3,\n",
    "                     padding='same',\n",
    "                     activation='relu',\n",
    "                     strides=1,\n",
    "                    kernel_initializer = 'glorot_uniform'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(LSTM(256, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))\n",
    "    model.add(LSTM(512, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(len(activities), activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UNet_LSTM():\n",
    "    optimizer = Adam(lr=1e-4)\n",
    "    inputs = Input((180, 6))\n",
    "  \n",
    "  # encoding phase\n",
    "    conv1 = Conv1D(32,\n",
    "                 3,\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 strides=1,\n",
    "                 kernel_initializer = 'glorot_uniform')(inputs)\n",
    "    conv2 = Conv1D(32,\n",
    "                 3,\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 strides=1,\n",
    "                 kernel_initializer = 'glorot_uniform')(conv1)\n",
    "    pool1 = MaxPooling1D(pool_size = 2)(conv2) # 90\n",
    "\n",
    "    conv3 = Conv1D(64,\n",
    "                 3,\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 strides=1,\n",
    "                 kernel_initializer = 'glorot_uniform')(pool1)\n",
    "    conv4 = Conv1D(64,\n",
    "                 3,\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 strides=1,\n",
    "                 kernel_initializer = 'glorot_uniform')(conv3)\n",
    "    pool2 = MaxPooling1D(pool_size = 2)(conv4) # 45\n",
    "\n",
    "    #   conv5 = Conv1D(128,\n",
    "    #                  3,\n",
    "    #                  padding='same',\n",
    "    #                  activation='relu',\n",
    "    #                  strides=1,\n",
    "    #                  kernel_initializer = 'glorot_uniform')(pool2)\n",
    "    #   conv6 = Conv1D(128,\n",
    "    #                  3,\n",
    "    #                  padding='same',\n",
    "    #                  activation='relu',\n",
    "    #                  strides=1,\n",
    "    #                  kernel_initializer = 'glorot_uniform')(conv5)\n",
    "    #   pool3 = MaxPooling1D(pool_size = 2)(conv6) # \n",
    "\n",
    "    # middle phase\n",
    "    conv7 = Conv1D(128,\n",
    "                 3,\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 strides=1,\n",
    "                 kernel_initializer = 'glorot_uniform')(pool2)\n",
    "    conv8 = Conv1D(128,\n",
    "                 3,\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 strides=1,\n",
    "                 kernel_initializer = 'glorot_uniform')(conv7)\n",
    "    drop1 = Dropout(0.5)(conv8)\n",
    "\n",
    "    # decoding phase\n",
    "    #   up1 = Conv1D(128,\n",
    "    #                  2,\n",
    "    #                  padding='same',\n",
    "    #                  activation='relu',\n",
    "    #                  strides=1,\n",
    "    #                  kernel_initializer = 'glorot_uniform')(UpSampling1D(size = 2)(drop1))\n",
    "    #   concat1 = Concatenate(axis=-1)([conv6, up1])\n",
    "    #   conv9 = Conv1D(128,\n",
    "    #                  3,\n",
    "    #                  padding='same',\n",
    "    #                  activation='relu',\n",
    "    #                  strides=1,\n",
    "    #                  kernel_initializer = 'glorot_uniform')(UpSampling1D(size = 2)(concat1))\n",
    "    #   conv10 = Conv1D(128,\n",
    "    #                  3,\n",
    "    #                  padding='same',\n",
    "    #                  activation='relu',\n",
    "    #                  strides=1,\n",
    "    #                  kernel_initializer = 'glorot_uniform')(UpSampling1D(size = 2)(conv9))\n",
    "\n",
    "    up2 = Conv1D(64,\n",
    "               2,\n",
    "               padding='same',\n",
    "               activation='relu',\n",
    "               strides=1,\n",
    "               kernel_initializer = 'glorot_uniform')(UpSampling1D(size = 2)(drop1))\n",
    "    concat2 = Concatenate(axis=-1)([conv4, up2])\n",
    "    conv11 = Conv1D(64,\n",
    "                 3,\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 strides=1,\n",
    "                 kernel_initializer = 'glorot_uniform')(concat2)\n",
    "    conv12 = Conv1D(64,\n",
    "                 3,\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 strides=1,\n",
    "                 kernel_initializer = 'glorot_uniform')(conv11)\n",
    "\n",
    "    up3 = Conv1D(32,\n",
    "               2,\n",
    "               padding='same',\n",
    "               activation='relu',\n",
    "               strides=1,\n",
    "               kernel_initializer = 'glorot_uniform')(UpSampling1D(size = 2)(conv12))\n",
    "    concat3 = Concatenate(axis=-1)([conv2, up3])\n",
    "    conv13 = Conv1D(32,\n",
    "                 3,\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 strides=1,\n",
    "                 kernel_initializer = 'glorot_uniform')(concat3)\n",
    "    conv14 = Conv1D(128,\n",
    "                 3,\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 strides=1,\n",
    "                 kernel_initializer = 'glorot_uniform')(conv13)\n",
    "\n",
    "    # classification Level\n",
    "    lstm1 = LSTM(256, return_sequences=True, dropout=0.5, recurrent_dropout=0.5)(conv14)\n",
    "    lstm2 = LSTM(512, return_sequences=True, dropout=0.5, recurrent_dropout=0.5)(lstm1)\n",
    "    flat1 = Flatten()(lstm2)\n",
    "\n",
    "    dense1 = Dense(len(activities), activation='softmax')(flat1)\n",
    "\n",
    "    model = Model(input = inputs, output = dense1, name = 'UNet_LSTM')\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 180, 6)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 180, 32)      608         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 180, 32)      3104        conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 90, 32)       0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 90, 64)       6208        max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 90, 64)       12352       conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 45, 64)       0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 45, 128)      24704       max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 45, 128)      49280       conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 45, 128)      0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_1 (UpSampling1D)  (None, 90, 128)      0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 90, 64)       16448       up_sampling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 90, 128)      0           conv1d_4[0][0]                   \n",
      "                                                                 conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 90, 64)       24640       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 90, 64)       12352       conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_2 (UpSampling1D)  (None, 180, 64)      0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 180, 32)      4128        up_sampling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 180, 64)      0           conv1d_2[0][0]                   \n",
      "                                                                 conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 180, 32)      6176        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 180, 128)     12416       conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_9 (LSTM)                   (None, 180, 256)     394240      conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_10 (LSTM)                  (None, 180, 512)     1574912     lstm_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 92160)        0           lstm_10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 27)           2488347     flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,629,915\n",
      "Trainable params: 4,629,915\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/renjie/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:131: UserWarning: Update your `Model` call to the Keras 2 API: `Model(name=\"UNet_LSTM\", inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "# model = simple_LSTM()\n",
    "# model = bidirectional_LSTM()\n",
    "# model = conv2_LSTM()\n",
    "model = UNet_LSTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_DIR = os.path.join(os.getcwd(), 'logs')\n",
    "tb = TensorBoard(LOG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_dir = 'weights/' + model.name + \\\n",
    "            '-{epoch:02d}-{loss:.2f}.hdf5'\n",
    "chkpt = ModelCheckpoint(filepath=weights_dir, monitor='loss', save_best_only=True, save_weights_only=True, mode='auto', period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_acc', min_delta=0, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, Y_train, epochs=20, batch_size=3, validation_data = (X_test, Y_test), callbacks=[tb, chkpt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "plt.plot(train_acc, 'C0')\n",
    "plt.plot(val_acc, 'C1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = history.history['loss']\n",
    "val_acc = history.history['val_loss']\n",
    "plt.plot(train_acc, 'C0')\n",
    "plt.plot(val_acc, 'C1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1 = np.argmax(model.predict(X_test), axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = ['swipe to the left',\n",
    "               'swipe to the right',\n",
    "               'wave',\n",
    "               'front clap',\n",
    "               'throw',\n",
    "               'cross arms',\n",
    "               'basketball shoot',\n",
    "               'draw x',\n",
    "               'draw circle (CW)',\n",
    "               'draw circle (CCW)',\n",
    "               'draw triangle',\n",
    "               'bowling',\n",
    "               'boxing',\n",
    "               'baseball swing',\n",
    "               'tennis swing',\n",
    "               'arm curl',\n",
    "               'tennis serve',\n",
    "               'two hand push',\n",
    "               'knock door',\n",
    "               'catch',\n",
    "               'pick and throw',\n",
    "               'jogging',\n",
    "               'walking',\n",
    "               'sit to stand',\n",
    "               'stand to sit',\n",
    "               'forward lunge',\n",
    "               'squat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_1 = confusion_matrix(np.argmax(Y_test, axis = -1), pred_1)\n",
    "NUM_LABELS = 27\n",
    "\n",
    "f, axes = plt.subplots(1,1, figsize = (12,12))\n",
    "axes.set_xlabel('Actual')\n",
    "axes.set_ylabel('Predicted')\n",
    "axes.grid(False)\n",
    "axes.set_xticklabels(class_labels, rotation = 90)\n",
    "axes.set_yticklabels(class_labels)\n",
    "axes.set_yticks(list(range(27)))\n",
    "axes.set_xticks(list(range(27)))\n",
    "plt.imshow(confusion_1, cmap=plt.cm.Set2, interpolation='nearest')\n",
    "\n",
    "for i, cas in enumerate(confusion_1):\n",
    "    for j, count in enumerate(cas):\n",
    "        if count > 0:\n",
    "            xoff = .07 * len(str(count))\n",
    "            plt.text(j-xoff, i+.2, int(count), fontsize=12, color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seeing if there is a bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(inertial_path)):\n",
    "    test = sio.loadmat(inertial_path[i])['d_iner']\n",
    "    test = np.expand_dims(np.swapaxes(sequence.pad_sequences(np.swapaxes(test,1,0), maxlen= 326), 1, 0), axis =0)\n",
    "    pred = model.predict(test)\n",
    "    print('Predicted: {} Expected: [{}]'.format(np.argmax(pred, axis = -1) + 1, get_action_number(inertial_path[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 810"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = sio.loadmat(inertial_path[num])['d_iner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.expand_dims(np.swapaxes(sequence.pad_sequences(np.swapaxes(test,1,0), maxlen= 326), 1, 0), axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(pred, axis = -1), inertial_path[num].split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
